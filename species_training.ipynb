{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Geospatial\n",
    "import contextily as cx\n",
    "from shapely.geometry import Point, Polygon\n",
    "import xarray as xr\n",
    "import rasterio.features\n",
    "import rasterio as rio\n",
    "\n",
    "# API\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Import Planetary Computer\n",
    "import fsspec\n",
    "import stackstac\n",
    "import pystac\n",
    "import pystac_client\n",
    "import planetary_computer\n",
    "\n",
    "# Other\n",
    "import os\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"training_data/occurrence.txt\"\n",
    "country = \"AU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Sort acc to country -> Australia\n",
    "    dataset = get_Dataset()\n",
    "\n",
    "    # ecological features from planetary database\n",
    "    # final_dataset acts as x_test\n",
    "    final_dataset = getFinalFeatures(dataset.longitude, dataset.latitude)\n",
    "\n",
    "    # predictions\n",
    "    OccurPredictions = model.predict(final_dataset)\n",
    "\n",
    "    # Plot results\n",
    "    # 1. Probability occurences\n",
    "    # 2. Species occurrences according to geographical features\n",
    "    plot_prob(OccurPredictions, final_dataset)\n",
    "    plot_graphs(OccurPredictions, final_dataset)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path, sep='\\t', parse_dates=['eventDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crinia signifera             126657\n",
       "Litoria fallax                47332\n",
       "Crinia glauerti                9393\n",
       "Ranoidea australis             4097\n",
       "Agalychnis callidryas          2212\n",
       "Dendrobates auratus            1718\n",
       "Xenopus laevis                 1139\n",
       "Chiromantis xerampelina         702\n",
       "Austrochaperina pluvialis       541\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_species(dataset_path, year_range=(2000,2022), bbox=None, chosenCountry=\"AU\"):\n",
    "    \"\"\"Returns the dataframe of all frog occurrences for the bounding box specified.\"\"\"\n",
    "    columns = [\n",
    "        'eventDate','countryCode','decimalLatitude','decimalLongitude','species'\n",
    "    ]\n",
    "    species = pd.read_csv(dataset_path, sep='\\t', parse_dates=['eventDate'])\n",
    "    species = species[species['countryCode'] == chosenCountry][columns]\n",
    "    species = species[lambda x: \n",
    "            (x.eventDate.dt.year >= year_range[0]) & \n",
    "            (x.eventDate.dt.year <= year_range[1])\n",
    "        ]\n",
    "    print(\"Shape of occurrence dataset: \",species.shape)\n",
    "    return species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terraclimate(bbox, metrics, time_slice=('2000-01-01','2022-02-01'), assets=None, features=None, interp_dims=(1024,1024), verbose=True):\n",
    "    \"\"\"Returns terraclimate metrics for a given area, allowing results to be interpolated onto a larger image.\n",
    "    \n",
    "    Attributes:\n",
    "    bbox -- Tuple of (min_lon, min_lat, max_lon, max_lat) to define area\n",
    "    metrics -- Nested dictionary in the form {<metric_name>:{'fn':<metric_function>,'params':<metric_kwargs_dict>}, ... }\n",
    "    time_slice -- Tuple of datetime strings to select data between, e.g. ('2015-01-01','2019-12-31')\n",
    "    assets -- list of terraclimate assets to take\n",
    "    features -- list of asset metrics to take, specified by strings in the form '<asset_name>_<metric_name>'\n",
    "    interp_dims -- Tuple of dimensions (n, m) to interpolate results to\n",
    "    \"\"\"\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    \n",
    "    collection = pystac.read_file(\"https://planetarycomputer.microsoft.com/api/stac/v1/collections/terraclimate\")\n",
    "    asset = collection.assets[\"zarr-https\"]\n",
    "    store = fsspec.get_mapper(asset.href)\n",
    "    data = xr.open_zarr(store, **asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "    print(data)\n",
    "    \n",
    "    # Select datapoints that overlap region\n",
    "    if time_slice is not None:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat),time=slice(time_slice[0],time_slice[1]))\n",
    "    else:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat))\n",
    "    if assets is not None:\n",
    "        data = data[assets]\n",
    "    \n",
    "    print('Loading data') if verbose else None\n",
    "    data = data.rename(lat='y', lon='x').to_array().compute()\n",
    "        \n",
    "    # Calculate metrics\n",
    "    combined_values = []\n",
    "    combined_bands = []\n",
    "    for name, metric in metrics.items():\n",
    "        print(f'Calculating {name}') if verbose else None\n",
    "        sum_data = xr.apply_ufunc(\n",
    "            metric['fn'], data, input_core_dims=[[\"time\"]], kwargs=metric['params'], dask = 'allowed', vectorize = True\n",
    "        ).rename(variable='band')\n",
    "        xcoords = sum_data.x\n",
    "        ycoords = sum_data.y\n",
    "        dims = sum_data.dims\n",
    "        combined_values.append(sum_data.values)\n",
    "        for band in sum_data.band.values:\n",
    "            combined_bands.append(band+'_'+name)\n",
    "        \n",
    "    # Combine metrics\n",
    "    combined_values = np.concatenate(\n",
    "        combined_values,\n",
    "        axis=0\n",
    "    )\n",
    "    combined_data = xr.DataArray(\n",
    "        data=combined_values,\n",
    "        dims=dims,\n",
    "        coords=dict(\n",
    "            band=combined_bands,\n",
    "            y=ycoords,\n",
    "            x=xcoords\n",
    "        )\n",
    "    )    \n",
    "\n",
    "    # Take relevant bands:\n",
    "    combined_data = combined_data.sel(band=features)\n",
    "    print(combined_data.shape)\n",
    "    print(combined_data.head)\n",
    "    \n",
    "    if interp_dims is not None:\n",
    "        print(f'Interpolating image') if verbose else None\n",
    "        interp_coords = (np.linspace(bbox[0], bbox[2], interp_dims[0]), np.linspace(bbox[1], bbox[3], interp_dims[1]))\n",
    "        combined_data = combined_data.interp(x=interp_coords[0], y=interp_coords[1], method='nearest', kwargs={\"fill_value\": \"extrapolate\"})\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of occurrence dataset:  (148379, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventDate</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>species</th>\n",
       "      <th>key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-23 01:38:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-32.719457</td>\n",
       "      <td>152.159267</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-29 13:57:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-26.714302</td>\n",
       "      <td>152.815096</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-04-18 19:05:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-33.693144</td>\n",
       "      <td>151.320884</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-07-28 17:16:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-27.888019</td>\n",
       "      <td>153.309342</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-05-05 10:56:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-35.208964</td>\n",
       "      <td>138.480985</td>\n",
       "      <td>Crinia signifera</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             eventDate countryCode  decimalLatitude  decimalLongitude  \\\n",
       "0  2020-01-23 01:38:00          AU       -32.719457        152.159267   \n",
       "4  2021-10-29 13:57:00          AU       -26.714302        152.815096   \n",
       "7  2018-04-18 19:05:00          AU       -33.693144        151.320884   \n",
       "8  2009-07-28 17:16:00          AU       -27.888019        153.309342   \n",
       "16 2021-05-05 10:56:00          AU       -35.208964        138.480985   \n",
       "\n",
       "             species  key  \n",
       "0     Litoria fallax    0  \n",
       "4     Litoria fallax    1  \n",
       "7     Litoria fallax    2  \n",
       "8     Litoria fallax    3  \n",
       "16  Crinia signifera    4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speciesData = get_species(dataset_path)\n",
    "\n",
    "target_species = \"Litoria fallax\"\n",
    "\n",
    "# CREATE NEW TARGET CLASS WHICH HAS BINARY VALUES\n",
    "\n",
    "speciesData['key'] = [i for i in range(speciesData.shape[0])]\n",
    "min_lat = speciesData.decimalLatitude.min()\n",
    "max_lat = speciesData.decimalLatitude.max()\n",
    "min_lon = speciesData.decimalLongitude.min()\n",
    "max_lon = speciesData.decimalLongitude.max()\n",
    "\n",
    "bbox = (min_lon, min_lat, max_lon, max_lat)\n",
    "speciesData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crinia signifera             94848\n",
       "Litoria fallax               43199\n",
       "Crinia glauerti               7984\n",
       "Ranoidea australis            2100\n",
       "Austrochaperina pluvialis      248\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speciesData.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventDate</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>species</th>\n",
       "      <th>key</th>\n",
       "      <th>Austrochaperina pluvialis</th>\n",
       "      <th>Crinia glauerti</th>\n",
       "      <th>Crinia signifera</th>\n",
       "      <th>Litoria fallax</th>\n",
       "      <th>Ranoidea australis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-23 01:38:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-32.719457</td>\n",
       "      <td>152.159267</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-29 13:57:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-26.714302</td>\n",
       "      <td>152.815096</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-04-18 19:05:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-33.693144</td>\n",
       "      <td>151.320884</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2009-07-28 17:16:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-27.888019</td>\n",
       "      <td>153.309342</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-05-05 10:56:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-35.208964</td>\n",
       "      <td>138.480985</td>\n",
       "      <td>Crinia signifera</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             eventDate countryCode  decimalLatitude  decimalLongitude  \\\n",
       "0  2020-01-23 01:38:00          AU       -32.719457        152.159267   \n",
       "4  2021-10-29 13:57:00          AU       -26.714302        152.815096   \n",
       "7  2018-04-18 19:05:00          AU       -33.693144        151.320884   \n",
       "8  2009-07-28 17:16:00          AU       -27.888019        153.309342   \n",
       "16 2021-05-05 10:56:00          AU       -35.208964        138.480985   \n",
       "\n",
       "             species  key  Austrochaperina pluvialis  Crinia glauerti  \\\n",
       "0     Litoria fallax    0                          0                0   \n",
       "4     Litoria fallax    1                          0                0   \n",
       "7     Litoria fallax    2                          0                0   \n",
       "8     Litoria fallax    3                          0                0   \n",
       "16  Crinia signifera    4                          0                0   \n",
       "\n",
       "    Crinia signifera  Litoria fallax  Ranoidea australis  \n",
       "0                  0               1                   0  \n",
       "4                  0               1                   0  \n",
       "7                  0               1                   0  \n",
       "8                  0               1                   0  \n",
       "16                 1               0                   0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot = pd.get_dummies(speciesData.species)\n",
    "df = pd.concat([speciesData, onehot], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = xr.load_dataarray('assets/weatherData_Aus.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:                 (time: 744, lat: 4320, lon: 8640, crs: 1)\n",
      "Coordinates:\n",
      "  * crs                     (crs) int16 3\n",
      "  * lat                     (lat) float64 89.98 89.94 89.9 ... -89.94 -89.98\n",
      "  * lon                     (lon) float64 -180.0 -179.9 -179.9 ... 179.9 180.0\n",
      "  * time                    (time) datetime64[ns] 1958-01-01 ... 2019-12-01\n",
      "Data variables: (12/18)\n",
      "    aet                     (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "    def                     (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "    pdsi                    (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "    pet                     (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "    ppt                     (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "    ppt_station_influence   (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "    ...                      ...\n",
      "    tmin                    (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "    tmin_station_influence  (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "    vap                     (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "    vap_station_influence   (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "    vpd                     (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "    ws                      (time, lat, lon) float32 dask.array<chunksize=(12, 1440, 1440), meta=np.ndarray>\n",
      "Loading data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [52], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39m# Features to take, in form '<asset>_<metric>'\u001b[39;00m\n\u001b[0;32m     21\u001b[0m features\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mtmax_mean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtmin_mean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mppt_mean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msoil_mean\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> 23\u001b[0m weather_data \u001b[39m=\u001b[39m get_terraclimate(bbox, tc_metrics, assets\u001b[39m=\u001b[39;49massets, features\u001b[39m=\u001b[39;49mfeatures)\n\u001b[0;32m     24\u001b[0m display(weather_data\u001b[39m.\u001b[39mband\u001b[39m.\u001b[39mvalues)\n",
      "Cell \u001b[1;32mIn [15], line 29\u001b[0m, in \u001b[0;36mget_terraclimate\u001b[1;34m(bbox, metrics, time_slice, assets, features, interp_dims, verbose)\u001b[0m\n\u001b[0;32m     26\u001b[0m     data \u001b[39m=\u001b[39m data[assets]\n\u001b[0;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLoading data\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m verbose \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mrename(lat\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m'\u001b[39;49m, lon\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mx\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mto_array()\u001b[39m.\u001b[39;49mcompute()\n\u001b[0;32m     31\u001b[0m \u001b[39m# Calculate metrics\u001b[39;00m\n\u001b[0;32m     32\u001b[0m combined_values \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\site-packages\\xarray\\core\\dataarray.py:1088\u001b[0m, in \u001b[0;36mDataArray.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[39m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m \u001b[39mremote source into memory and return a new array. The original is\u001b[39;00m\n\u001b[0;32m   1071\u001b[0m \u001b[39mleft unaltered.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mdask.compute\u001b[39;00m\n\u001b[0;32m   1086\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m new \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mreturn\u001b[39;00m new\u001b[39m.\u001b[39mload(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\site-packages\\xarray\\core\\dataarray.py:1062\u001b[0m, in \u001b[0;36mDataArray.load\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m: T_DataArray, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T_DataArray:\n\u001b[0;32m   1045\u001b[0m     \u001b[39m\"\"\"Manually trigger loading of this array's data from disk or a\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m \u001b[39m    remote source into memory and return this array.\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[39m    dask.compute\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1062\u001b[0m     ds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_temp_dataset()\u001b[39m.\u001b[39mload(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1063\u001b[0m     new \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_from_temp_dataset(ds)\n\u001b[0;32m   1064\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable \u001b[39m=\u001b[39m new\u001b[39m.\u001b[39m_variable\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\site-packages\\xarray\\core\\dataset.py:735\u001b[0m, in \u001b[0;36mDataset.load\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39marray\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mda\u001b[39;00m\n\u001b[0;32m    734\u001b[0m \u001b[39m# evaluate all the dask arrays simultaneously\u001b[39;00m\n\u001b[1;32m--> 735\u001b[0m evaluated_data \u001b[39m=\u001b[39m da\u001b[39m.\u001b[39mcompute(\u001b[39m*\u001b[39mlazy_data\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    737\u001b[0m \u001b[39mfor\u001b[39;00m k, data \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(lazy_data, evaluated_data):\n\u001b[0;32m    738\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables[k]\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m data\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\site-packages\\dask\\base.py:600\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    597\u001b[0m     keys\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_keys__())\n\u001b[0;32m    598\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m--> 600\u001b[0m results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    601\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\site-packages\\dask\\threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[1;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pool, multiprocessing\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mPool):\n\u001b[0;32m     87\u001b[0m         pool \u001b[39m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[1;32m---> 89\u001b[0m results \u001b[39m=\u001b[39m get_async(\n\u001b[0;32m     90\u001b[0m     pool\u001b[39m.\u001b[39msubmit,\n\u001b[0;32m     91\u001b[0m     pool\u001b[39m.\u001b[39m_max_workers,\n\u001b[0;32m     92\u001b[0m     dsk,\n\u001b[0;32m     93\u001b[0m     keys,\n\u001b[0;32m     94\u001b[0m     cache\u001b[39m=\u001b[39mcache,\n\u001b[0;32m     95\u001b[0m     get_id\u001b[39m=\u001b[39m_thread_get_id,\n\u001b[0;32m     96\u001b[0m     pack_exception\u001b[39m=\u001b[39mpack_exception,\n\u001b[0;32m     97\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m    100\u001b[0m \u001b[39m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\site-packages\\dask\\local.py:500\u001b[0m, in \u001b[0;36mget_async\u001b[1;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[39mwhile\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mwaiting\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mready\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m state[\u001b[39m\"\u001b[39m\u001b[39mrunning\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    499\u001b[0m     fire_tasks(chunksize)\n\u001b[1;32m--> 500\u001b[0m     \u001b[39mfor\u001b[39;00m key, res_info, failed \u001b[39min\u001b[39;00m queue_get(queue)\u001b[39m.\u001b[39mresult():\n\u001b[0;32m    501\u001b[0m         \u001b[39mif\u001b[39;00m failed:\n\u001b[0;32m    502\u001b[0m             exc, tb \u001b[39m=\u001b[39m loads(res_info)\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\site-packages\\dask\\local.py:130\u001b[0m, in \u001b[0;36mqueue_get\u001b[1;34m(q)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m         \u001b[39mreturn\u001b[39;00m q\u001b[39m.\u001b[39;49mget(block\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, timeout\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m    131\u001b[0m     \u001b[39mexcept\u001b[39;00m Empty:\n\u001b[0;32m    132\u001b[0m         \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[0;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Metrics to measure over time dimension\n",
    "tc_metrics = {\n",
    "    'mean':{\n",
    "        'fn':np.nanmean,\n",
    "        'params':{}\n",
    "    },\n",
    "    'min':{\n",
    "        'fn':np.nanmin,\n",
    "        'params':{}\n",
    "    },\n",
    "    'max':{\n",
    "        'fn':np.nanmax,\n",
    "        'params':{}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Measurements to take\n",
    "assets=['tmax', 'tmin', 'ppt', 'soil']\n",
    "\n",
    "# Features to take, in form '<asset>_<metric>'\n",
    "features=['tmax_mean', 'tmin_mean', 'ppt_mean', 'soil_mean']\n",
    "\n",
    "weather_data = get_terraclimate(bbox, tc_metrics, assets=assets, features=features)\n",
    "display(weather_data.band.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventDate</th>\n",
       "      <th>countryCode</th>\n",
       "      <th>decimalLatitude</th>\n",
       "      <th>decimalLongitude</th>\n",
       "      <th>species</th>\n",
       "      <th>key</th>\n",
       "      <th>Austrochaperina pluvialis</th>\n",
       "      <th>Crinia glauerti</th>\n",
       "      <th>Crinia signifera</th>\n",
       "      <th>Litoria fallax</th>\n",
       "      <th>Ranoidea australis</th>\n",
       "      <th>ppt_mean</th>\n",
       "      <th>soil_mean</th>\n",
       "      <th>tmax_mean</th>\n",
       "      <th>tmin_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-23 01:38:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-32.719457</td>\n",
       "      <td>152.159267</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>102.108330</td>\n",
       "      <td>136.166672</td>\n",
       "      <td>23.354586</td>\n",
       "      <td>13.663752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-29 13:57:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-26.714302</td>\n",
       "      <td>152.815096</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>103.104164</td>\n",
       "      <td>129.783340</td>\n",
       "      <td>24.437502</td>\n",
       "      <td>13.463335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-18 19:05:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-33.693144</td>\n",
       "      <td>151.320884</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97.562500</td>\n",
       "      <td>79.508331</td>\n",
       "      <td>23.269585</td>\n",
       "      <td>13.485835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-07-28 17:16:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-27.888019</td>\n",
       "      <td>153.309342</td>\n",
       "      <td>Litoria fallax</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>98.904167</td>\n",
       "      <td>90.849998</td>\n",
       "      <td>25.787504</td>\n",
       "      <td>15.002085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-05 10:56:00</td>\n",
       "      <td>AU</td>\n",
       "      <td>-35.208964</td>\n",
       "      <td>138.480985</td>\n",
       "      <td>Crinia signifera</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.445835</td>\n",
       "      <td>11.350000</td>\n",
       "      <td>21.426668</td>\n",
       "      <td>11.767502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            eventDate countryCode  decimalLatitude  decimalLongitude  \\\n",
       "0 2020-01-23 01:38:00          AU       -32.719457        152.159267   \n",
       "1 2021-10-29 13:57:00          AU       -26.714302        152.815096   \n",
       "2 2018-04-18 19:05:00          AU       -33.693144        151.320884   \n",
       "3 2009-07-28 17:16:00          AU       -27.888019        153.309342   \n",
       "4 2021-05-05 10:56:00          AU       -35.208964        138.480985   \n",
       "\n",
       "            species  key  Austrochaperina pluvialis  Crinia glauerti  \\\n",
       "0    Litoria fallax    0                          0                0   \n",
       "1    Litoria fallax    1                          0                0   \n",
       "2    Litoria fallax    2                          0                0   \n",
       "3    Litoria fallax    3                          0                0   \n",
       "4  Crinia signifera    4                          0                0   \n",
       "\n",
       "   Crinia signifera  Litoria fallax  Ranoidea australis    ppt_mean  \\\n",
       "0                 0               1                   0  102.108330   \n",
       "1                 0               1                   0  103.104164   \n",
       "2                 0               1                   0   97.562500   \n",
       "3                 0               1                   0   98.904167   \n",
       "4                 1               0                   0   37.445835   \n",
       "\n",
       "    soil_mean  tmax_mean  tmin_mean  \n",
       "0  136.166672  23.354586  13.663752  \n",
       "1  129.783340  24.437502  13.463335  \n",
       "2   79.508331  23.269585  13.485835  \n",
       "3   90.849998  25.787504  15.002085  \n",
       "4   11.350000  21.426668  11.767502  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_species(speciesData, data):\n",
    "    \"\"\"Collects the data for each frog location and joins it onto the frog data \n",
    "\n",
    "    Arguments:\n",
    "    speciesData -- dataframe containing the response variable along with [\"decimalLongitude\", \"decimalLatitude\", \"key\"]\n",
    "    data -- xarray dataarray of features, indexed with geocoordinates\n",
    "    \"\"\"\n",
    "    return speciesData.merge(\n",
    "        (\n",
    "            data\n",
    "            .rename('data')\n",
    "            .sel(\n",
    "                x=xr.DataArray(speciesData.decimalLongitude, dims=\"key\", coords={\"key\": speciesData.key}), \n",
    "                y=xr.DataArray(speciesData.decimalLatitude, dims=\"key\", coords={\"key\": speciesData.key}),\n",
    "                method=\"nearest\"\n",
    "            )\n",
    "            .to_dataframe()\n",
    "            .assign(val = lambda x: x.iloc[:, -1])\n",
    "            [['val']]\n",
    "            .reset_index()\n",
    "            .drop_duplicates()\n",
    "            .pivot(index=\"key\", columns=\"band\", values=\"val\")\n",
    "            .reset_index()\n",
    "        ),\n",
    "        on = ['key'],\n",
    "        how = 'inner'\n",
    "    )\n",
    "    \n",
    "model_data = join_species(df, weather_data)\n",
    "model_data = model_data\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.to_csv(\"assets/finalDataset_AllFrogs.csv\")\n",
    "# model_data = pd.read_csv(\"assets/finalDataset_AllFrogs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eventDate                    0\n",
      "countryCode                  0\n",
      "decimalLatitude              0\n",
      "decimalLongitude             0\n",
      "species                      0\n",
      "key                          0\n",
      "Austrochaperina pluvialis    0\n",
      "Crinia glauerti              0\n",
      "Crinia signifera             0\n",
      "Litoria fallax               0\n",
      "Ranoidea australis           0\n",
      "ppt_mean                     0\n",
      "soil_mean                    0\n",
      "tmax_mean                    0\n",
      "tmin_mean                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s = ['Austrochaperina pluvialis','Crinia glauerti','Crinia signifera','Litoria fallax','Ranoidea australis']\n",
    "print(model_data.isna().sum())\n",
    "model_data = model_data.dropna()\n",
    "# Separate the predictor variables from the response\n",
    "X = (\n",
    "    model_data\n",
    "    .drop(['eventDate', 'decimalLatitude', 'decimalLongitude', 'species',\n",
    "       'countryCode', 'key'], 1)\n",
    ")\n",
    "X.drop(s,1,inplace=True)\n",
    "y = model_data[s]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.to_csv(\"assets/frogTest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8458215201836101\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier().fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_pred, y_test))\n",
    "# print(f\"F1 Score: \",f1_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.iloc[:].values\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   44,     0,     0,     7,     0],\n",
       "       [    1,  1614,     3,     0,     0],\n",
       "       [    1,     0, 16325,  2599,     0],\n",
       "       [   11,     0,  1946,  6654,     0],\n",
       "       [    0,     0,     0,     0,   423]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test.values.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Visualise the results in a confusion matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m disp \u001b[39m=\u001b[39m ConfusionMatrixDisplay\u001b[39m.\u001b[39;49mfrom_estimator(rf, x_test, y_test, display_labels\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mAbsent\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mPresent\u001b[39;49m\u001b[39m'\u001b[39;49m], cmap\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mBlues\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m disp\u001b[39m.\u001b[39mfigure_\u001b[39m.\u001b[39mset_size_inches((\u001b[39m7\u001b[39m, \u001b[39m7\u001b[39m))\n\u001b[0;32m      4\u001b[0m disp\u001b[39m.\u001b[39max_\u001b[39m.\u001b[39mset_title(\u001b[39m'\u001b[39m\u001b[39mRandom Forest Classifier\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:294\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.from_estimator\u001b[1;34m(cls, estimator, X, y, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmethod_name\u001b[39m}\u001b[39;00m\u001b[39m only supports classifiers\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    292\u001b[0m y_pred \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m--> 294\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_predictions(\n\u001b[0;32m    295\u001b[0m     y,\n\u001b[0;32m    296\u001b[0m     y_pred,\n\u001b[0;32m    297\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    298\u001b[0m     labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m    299\u001b[0m     normalize\u001b[39m=\u001b[39;49mnormalize,\n\u001b[0;32m    300\u001b[0m     display_labels\u001b[39m=\u001b[39;49mdisplay_labels,\n\u001b[0;32m    301\u001b[0m     include_values\u001b[39m=\u001b[39;49minclude_values,\n\u001b[0;32m    302\u001b[0m     cmap\u001b[39m=\u001b[39;49mcmap,\n\u001b[0;32m    303\u001b[0m     ax\u001b[39m=\u001b[39;49max,\n\u001b[0;32m    304\u001b[0m     xticks_rotation\u001b[39m=\u001b[39;49mxticks_rotation,\n\u001b[0;32m    305\u001b[0m     values_format\u001b[39m=\u001b[39;49mvalues_format,\n\u001b[0;32m    306\u001b[0m     colorbar\u001b[39m=\u001b[39;49mcolorbar,\n\u001b[0;32m    307\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\site-packages\\sklearn\\metrics\\_plot\\confusion_matrix.py:423\u001b[0m, in \u001b[0;36mConfusionMatrixDisplay.from_predictions\u001b[1;34m(cls, y_true, y_pred, labels, sample_weight, normalize, display_labels, include_values, xticks_rotation, values_format, cmap, ax, colorbar)\u001b[0m\n\u001b[0;32m    420\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    421\u001b[0m         display_labels \u001b[39m=\u001b[39m labels\n\u001b[1;32m--> 423\u001b[0m cm \u001b[39m=\u001b[39m confusion_matrix(\n\u001b[0;32m    424\u001b[0m     y_true,\n\u001b[0;32m    425\u001b[0m     y_pred,\n\u001b[0;32m    426\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m    427\u001b[0m     labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m    428\u001b[0m     normalize\u001b[39m=\u001b[39;49mnormalize,\n\u001b[0;32m    429\u001b[0m )\n\u001b[0;32m    431\u001b[0m disp \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(confusion_matrix\u001b[39m=\u001b[39mcm, display_labels\u001b[39m=\u001b[39mdisplay_labels)\n\u001b[0;32m    433\u001b[0m \u001b[39mreturn\u001b[39;00m disp\u001b[39m.\u001b[39mplot(\n\u001b[0;32m    434\u001b[0m     include_values\u001b[39m=\u001b[39minclude_values,\n\u001b[0;32m    435\u001b[0m     cmap\u001b[39m=\u001b[39mcmap,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    439\u001b[0m     colorbar\u001b[39m=\u001b[39mcolorbar,\n\u001b[0;32m    440\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\KSGS\\anaconda3\\envs\\sdm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:309\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    307\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    308\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 309\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    312\u001b[0m     labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "\u001b[1;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "# Visualise the results in a confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_estimator(rf, x_test, y_test, display_labels=['Absent', 'Present'], cmap='Blues')\n",
    "disp.figure_.set_size_inches((7, 7))\n",
    "disp.ax_.set_title('Random Forest Classifier')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(rf,open(\"assets/randomforest_allfrog.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdm",
   "language": "python",
   "name": "sdm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
